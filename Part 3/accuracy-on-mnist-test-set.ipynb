{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "train_dir = r'C:\\Users\\harekrushna\\Documents\\internship\\MIDAS TASKS\\MIDAS TASK 2\\Part 3\\mnistTask'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". Read the picture files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".Decode the JPEG content to RGB grids of pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".Convert these into floating point tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".Rescale the pixel values (b/w 0 and 255) to the [0, 1] intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link : https://keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generating batches of tensor image data\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size = (28, 28),\n",
    "        batch_size = 20,\n",
    "        class_mode = 'sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the structure of CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Part 2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model in part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"C:\\\\Users\\\\harekrushna\\\\Documents\\\\internship\\\\MIDAS TASKS\\\\MIDAS TASK 2\\\\Part 2\\\\part2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 128,266\n",
      "Trainable params: 128,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist dataset\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot first few mnist test images\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(x_test[i], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reshape\n",
    "\n",
    "x_test = x_test.reshape((10000, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalization\n",
    "\n",
    "x_test_n = x_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step is to compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "             optimizer = optimizers.RMSprop(lr=1e-4),\n",
    "             metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 651us/sample - loss: 0.0657 - acc: 0.9863\n"
     ]
    }
   ],
   "source": [
    "ev = model.evaluate(x_test_n, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06569528349398787, 0.9863]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting an accuracy of around 98.63% with the part2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as k\n",
    "k.clear_session()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Part 1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model in part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"C:\\\\Users\\\\harekrushna\\\\Documents\\\\internship\\\\MIDAS TASKS\\\\MIDAS TASK 2\\\\Part 1\\\\part1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 163,850\n",
      "Trainable params: 163,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step is to compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "             optimizer = optimizers.RMSprop(lr=1e-4),\n",
    "             metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 613us/sample - loss: 2.3018 - acc: 0.1008s - loss: 2.3018 - acc: 0.100\n"
     ]
    }
   ],
   "source": [
    "ev = model.evaluate(x_test_n, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.301796018600464, 0.1008]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting an accuracy of around 10.08% with the part1 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as k\n",
    "k.clear_session()\n",
    "del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
